{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.api.types import union_categoricals\n",
    "from itertools import islice\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oews_path = Path('../Data/oews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict with list of MSA files within each folder-year\n",
    "oews_path_dict = {}\n",
    "for folder in Path(oews_path).iterdir():\n",
    "    folder_name = folder.name\n",
    "    year = re.findall(r'\\d+', folder_name)[0]\n",
    "    \n",
    "    if year == '97' or year == '98' or year == '99':\n",
    "        year = '19' + year\n",
    "    else:\n",
    "        year = '20' + year\n",
    "\n",
    "    file_list = []\n",
    "    for file in Path(folder).iterdir():\n",
    "        file_name = file.name\n",
    "        file_prefix = file_name[0:3]\n",
    "\n",
    "        # All MSA files is prefixed with 'msa' or 'MSA', except for 1997, which has 'oes' prefix\n",
    "        # Non-metro areas are in separate file with 'BOS' prefix beginning in 2006\n",
    "        if file_prefix == 'msa' or file_prefix == 'MSA' or file_prefix == 'oes' or file_prefix == 'BOS':\n",
    "            file_list.append(file)\n",
    "\n",
    "    oews_path_dict[year] = file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory we are storing processed dataframes in binary format, for quick access later\n",
    "binary_path = Path('../binaries/')\n",
    "binary_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Dict to store paths to processed binaries\n",
    "oews_binary_path_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables we want to store as strings\n",
    "oews_dtype_dict = {\n",
    "    'area': 'string',\n",
    "    'area_name': 'string',\n",
    "    'occ_code': 'string',\n",
    "    'occ_title': 'string'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for year 2000.\n",
      "Loading files for year 2001.\n",
      "Loading files for year 2002.\n",
      "Loading files for year 1997.\n",
      "Loading files for year 1998.\n",
      "Loading files for year 1999.\n",
      "Loading files for year 2003.\n",
      "Loading files for year 2004.\n",
      "Loading files for year 2005.\n",
      "Loading files for year 2006.\n",
      "Loading files for year 2007.\n",
      "Loading files for year 2008.\n",
      "Loading files for year 2009.\n",
      "Loading files for year 2010.\n",
      "Loading files for year 2011.\n",
      "Loading files for year 2012.\n",
      "Loading files for year 2013.\n",
      "Loading files for year 2014.\n",
      "Loading files for year 2015.\n",
      "Loading files for year 2016.\n",
      "Loading files for year 2017.\n",
      "Loading files for year 2018.\n",
      "Loading files for year 2019.\n",
      "Loading files for year 2020.\n",
      "Loading files for year 2021.\n"
     ]
    }
   ],
   "source": [
    "oews_df = pd.DataFrame()\n",
    "for year, file_list in oews_path_dict.items():\n",
    "    file_list_df_dict = {} # Dict to store all relevant dfs in each year-folder to be concatenated into a single year df\n",
    "\n",
    "    print(f'Loading files for year {year}.')\n",
    "    \n",
    "    for file_path in file_list:\n",
    "\n",
    "        # Prior to 2001, field descriptions were placed in the header rows\n",
    "\n",
    "        if int(year) < 2001:\n",
    "            df = pd.read_excel(file_path, dtype = str)\n",
    "\n",
    "            header_row = df['Unnamed: 0'].isna().values.argmin() # Find first row that is non-empty in first column, which should be the header row\n",
    "            header = df.iloc[header_row]\n",
    "\n",
    "            # Create new df without field description and header rows, and new headers\n",
    "            new_df = df.iloc[header_row + 1:]\n",
    "            new_df = new_df.rename(columns = header)\n",
    "            \n",
    "        else:\n",
    "            new_df = pd.read_excel(file_path, header = 0, dtype = str)\n",
    "\n",
    "        # Keep only columns we want and store in df dict\n",
    "        # For year 2000, occ_title has a typo\n",
    "        if int(year) == 2000:\n",
    "            new_df.rename(columns = {'occ_titl': 'occ_title'}, inplace = True)\n",
    "\n",
    "        new_df.columns = new_df.columns.str.lower() # Convert to lowercase column titles for all years\n",
    "\n",
    "        # For years 1998-2002, wage percentile columns had 'h_wpct' and 'a_wpct' prefixes\n",
    "        if 1997 < int(year) < 2003:\n",
    "            new_df.rename(columns = {'h_wpct10': 'h_pct10', 'h_wpct25': 'h_pct25', 'h_wpct75': 'h_pct75', 'h_wpct90': 'h_pct90', 'a_wpct10': 'a_pct10', 'a_wpct25': 'a_pct25', 'a_wpct75': 'a_pct75', 'a_wpct90': 'a_pct90'}, inplace = True)\n",
    "\n",
    "        # Starting in 2019, area_name was changed to area_title\n",
    "        if int(year) >= 2019:\n",
    "            new_df.rename(columns = {'area_title': 'area_name'}, inplace = True)\n",
    "\n",
    "        if int(year) != 1997:\n",
    "            new_df = new_df[['area', 'area_name', 'occ_code', 'occ_title', 'tot_emp', 'h_mean', 'a_mean', 'h_pct10', 'h_pct25', 'h_median', 'h_pct75', 'h_pct90', 'a_pct10', 'a_pct25', 'a_median', 'a_pct75', 'a_pct90']]\n",
    "        else:\n",
    "            new_df = new_df[['area', 'area_name', 'occ_code', 'occ_title', 'tot_emp', 'h_mean', 'a_mean', 'h_median']]\n",
    "        \n",
    "        file_list_df_dict[file_path.name] = new_df\n",
    "\n",
    "    combined_df = pd.concat([df for df in file_list_df_dict.values()]) # Concat all dfs into one\n",
    "    combined_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # Convert total employment counts and mean wages into numeric\n",
    "    combined_df['tot_emp'] = pd.to_numeric(combined_df['tot_emp'], errors = 'coerce')\n",
    "    combined_df['a_mean'] = pd.to_numeric(combined_df['a_mean'], errors = 'coerce')\n",
    "\n",
    "    # Area code may have leading whitespace for 1999 and 2000\n",
    "    combined_df['area'] = combined_df['area'].str.strip(' ')\n",
    "\n",
    "    # Add year column\n",
    "    combined_df['year'] = int(year)\n",
    "\n",
    "    # Concat all years into one df\n",
    "    oews_df = pd.concat([oews_df, combined_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined df as parquet\n",
    "target_path = binary_path.joinpath('oews.parquet')\n",
    "oews_df.to_parquet(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66d5af86484dd3eb1e0c3cb9b820c7e09a8aec6ddb6ff3dcf13084cc7d17f74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
