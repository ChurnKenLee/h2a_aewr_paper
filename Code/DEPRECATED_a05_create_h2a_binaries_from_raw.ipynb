{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.api.types import union_categoricals\n",
    "from itertools import islice\n",
    "import re\n",
    "import addfips\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "DC_STATEHOOD = 1 # Enables DC to be included in the state list\n",
    "import us\n",
    "import pickle\n",
    "import rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Census geographic codes file\n",
    "census_county = pd.read_csv(\"../Data/census_geography_codes/national_county2020.txt\", sep='|', dtype = 'string', keep_default_na=False).apply(lambda x: x.str.upper())\n",
    "census_countysub = pd.read_csv(\"../Data/census_geography_codes/national_cousub2020.txt\", sep='|', dtype = 'string', keep_default_na=False).apply(lambda x: x.str.upper())\n",
    "census_place = pd.read_csv(\"../Data/census_geography_codes/national_place2020.txt\", sep='|', dtype = 'string', keep_default_na=False).apply(lambda x: x.str.upper())\n",
    "census_placebycounty = pd.read_csv(\"../Data/census_geography_codes/national_place_by_county2020.txt\", sep='|', dtype = 'string', keep_default_na=False).apply(lambda x: x.str.upper())\n",
    "census_zip = pd.read_csv(\"../Data/census_geography_codes/tab20_zcta520_county20_natl.txt\", sep='|', dtype = 'string', keep_default_na=False).apply(lambda x: x.str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FIPS column\n",
    "census_county['fips'] = census_county['STATEFP'] + census_county['COUNTYFP']\n",
    "census_placebycounty['fips'] = census_placebycounty['STATEFP'] + census_placebycounty['COUNTYFP']\n",
    "census_zip['fips'] = census_zip['GEOID_COUNTY_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be places and ZIP codes that map to multiple counties; collapse these into unique entries\n",
    "census_county = census_county[['STATE', 'COUNTYNAME', 'fips']]\n",
    "census_place_agg = census_placebycounty.groupby(['STATE', 'COUNTYNAME', 'PLACENAME']).agg({'fips':lambda x: \",\".join(x)}).reset_index()\n",
    "census_zip_agg = census_zip.groupby(['GEOID_ZCTA5_20']).agg({'fips':lambda x: \",\".join(x)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty entries\n",
    "census_county = census_county[census_county['COUNTYNAME'] != '']\n",
    "census_place_agg = census_place_agg[census_place_agg['PLACENAME'] != '']\n",
    "census_zip_agg = census_zip_agg[census_zip_agg['GEOID_ZCTA5_20'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of H-2A program disclosure files from the DOL-OFLC\n",
    "h2a_file_name_dict = {\n",
    "    '2008':'H2A_FY2008.xlsx',\n",
    "    '2009':'H2A_FY2009.xlsx',\n",
    "    '2010':'H-2A_FY2010.xlsx',\n",
    "    '2011':'H-2A_FY2011.xlsx',\n",
    "    '2012':'H-2A_FY2012.xlsx',\n",
    "    '2013':'H2A_FY2013.xls',\n",
    "    '2014':'H-2A_FY14_Q4.xlsx',\n",
    "    '2015':'H-2A_Disclosure_Data_FY15_Q4.xlsx',\n",
    "    '2016':'H-2A_Disclosure_Data_FY16_updated.xlsx',\n",
    "    '2017':'H-2A_Disclosure_Data_FY17.xlsx',\n",
    "    '2018':'H-2A_Disclosure_Data_FY2018_EOY.xlsx',\n",
    "    '2019':'H-2A_Disclosure_Data_FY2019.xlsx',\n",
    "    '2020':'H-2A_Disclosure_Data_FY2020.xlsx',\n",
    "    '2021':'H-2A_Disclosure_Data_FY2021.xlsx',\n",
    "    '2022':'H-2A_Disclosure_Data_FY2022_Q4.xlsx',\n",
    "    '2023':'H-2A_Disclosure_Data_FY2023_Q4.xlsx',\n",
    "    '2024':'H-2A_Disclosure_Data_FY2024_Q4.xlsx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common set of variables we want from every fiscal year, and their types\n",
    "# We want all as string type, but some dates cannot be read as string type due to storage as date type in Excel, so strip the trailing time later\n",
    "h2a_dtype_dict = {}\n",
    "\n",
    "h2a_dtype_dict['2008'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'ALIEN_WORK_CITY':'string',\n",
    "    'ALIEN_WORK_STATE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2009'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'ALIEN_WORK_CITY':'string',\n",
    "    'ALIEN_WORK_STATE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2010'] = h2a_dtype_dict['2009']\n",
    "\n",
    "h2a_dtype_dict['2011'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'ALIEN_WORK_CITY':'string',\n",
    "    'ALIEN_WORK_STATE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2012'] = h2a_dtype_dict['2011']\n",
    "\n",
    "h2a_dtype_dict['2013'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'ALIEN_WORK_CITY':'string',\n",
    "    'ALIEN_WORK_STATE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2014'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_LOCATION_CITY':'string',\n",
    "    'WORKSITE_LOCATION_STATE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2015'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'CERTIFICATION_BEGIN_DATE':'string',\n",
    "    'CERTIFICATION_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'ORGANIZATION_FLAG':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2016'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'JOB_START_DATE':'string',\n",
    "    'JOB_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'ORGANIZATION_FLAG':'string',\n",
    "    'PRIMARY/SUB':'string',\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2017'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'JOB_START_DATE':'string', \n",
    "    'JOB_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_COUNTY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'ORGANIZATION_FLAG':'string',\n",
    "    'PRIMARY/SUB':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2018'] = {\n",
    "    'CASE_NO':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'JOB_START_DATE':'string', \n",
    "    'JOB_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_COUNTY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'ORGANIZATION_FLAG':'string',\n",
    "    'PRIMARY_SUB':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2019'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'NBR_WORKERS_REQUESTED':'string',\n",
    "    'NBR_WORKERS_CERTIFIED':'string',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'object',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'object',\n",
    "    'JOB_START_DATE':'string', \n",
    "    'JOB_END_DATE':'string',\n",
    "    'BASIC_NUMBER_OF_HOURS':'string',\n",
    "    'BASIC_RATE_OF_PAY':'string',\n",
    "    'BASIC_UNIT_OF_PAY':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_COUNTY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'ORGANIZATION_FLAG':'string',\n",
    "    'PRMARY/SUB':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2020'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'TOTAL_WORKERS_NEEDED':'string',\n",
    "    'TOTAL_WORKERS_H2A_REQUESTED':'string',\n",
    "    'TOTAL_WORKERS_H2A_CERTIFIED':'string',\n",
    "    'REQUESTED_BEGIN_DATE':'string',\n",
    "    'REQUESTED_END_DATE':'string',\n",
    "    'EMPLOYMENT_BEGIN_DATE':'string',\n",
    "    'EMPLOYMENT_END_DATE':'string',\n",
    "    'ANTICIPATED_NUMBER_OF_HOURS':'string',\n",
    "    'WAGE_OFFER':'string',\n",
    "    'PER':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_COUNTY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'TYPE_OF_EMPLOYER_APPLICATION':'string',\n",
    "    'H2A_LABOR_CONTRACTOR':'string'\n",
    "}\n",
    "\n",
    "h2a_dtype_dict['2021'] = h2a_dtype_dict['2020']\n",
    "h2a_dtype_dict['2022'] = h2a_dtype_dict['2020']\n",
    "h2a_dtype_dict['2023'] = h2a_dtype_dict['2020']\n",
    "\n",
    "h2a_dtype_dict['2024'] = {\n",
    "    'CASE_NUMBER':'string',\n",
    "    'CASE_STATUS':'string',\n",
    "    'EMPLOYER_NAME':'string',\n",
    "    'EMPLOYER_CITY':'string',\n",
    "    'EMPLOYER_STATE':'string',\n",
    "    'EMPLOYER_POSTAL_CODE':'string',\n",
    "    'TOTAL_WORKERS_NEEDED':'string',\n",
    "    'TOTAL_WORKERS_H2A_REQUESTED':'string',\n",
    "    'TOTAL_WORKERS_H2A_CERTIFIED':'string',\n",
    "    'REQUESTED_BEGIN_DATE':'string',\n",
    "    'REQUESTED_END_DATE':'string',\n",
    "    'EMPLOYMENT_BEGIN_DATE':'string',\n",
    "    'EMPLOYMENT_END_DATE':'string',\n",
    "    'ANTICIPATED_NUMBER_OF_HOURS':'string',\n",
    "    'WAGE_OFFER':'string',\n",
    "    'PER':'string',\n",
    "    'WORKSITE_CITY':'string',\n",
    "    'WORKSITE_COUNTY':'string',\n",
    "    'WORKSITE_STATE':'string',\n",
    "    'WORKSITE_POSTAL_CODE':'string',\n",
    "    'TYPE_OF_EMPLOYER_APPLICATION':'string',\n",
    "    'AG_ASSN_OR_AGENCY_STATUS':'string',\n",
    "    'H2A_LABOR_CONTRACTOR':'string'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2a_df_dict = {}\n",
    "# for year, file_name in h2a_file_name_dict.items():\n",
    "#     h2a_path = Path(f\"../Data/h2a/{file_name}\")\n",
    "#     print(h2a_path)\n",
    "\n",
    "#     dtype_dict = h2a_dtype_dict[year]\n",
    "#     col_list = list(dtype_dict.keys())\n",
    "#     h2a_df_dict[year] = pd.read_excel(h2a_path, usecols = col_list, dtype = dtype_dict, parse_dates=False)\n",
    "\n",
    "# # Pickling\n",
    "# with open(\"h2a_pickle\", \"wb\") as fp:\n",
    "#     pickle.dump(h2a_df_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling\n",
    "with open(\"h2a_pickle\", \"rb\") as fp:\n",
    "    h2a_df_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of common names for concatenating\n",
    "h2a_rename_dict = {\n",
    "    'CASE_NO':'case_number',\n",
    "    'CASE_NUMBER':'case_number',\n",
    "    'CASE_STATUS':'case_status',\n",
    "    'EMPLOYER_NAME':'employer_name',\n",
    "    'EMPLOYER_CITY':'employer_city',\n",
    "    'EMPLOYER_STATE':'employer_state',\n",
    "    'EMPLOYER_POSTAL_CODE':'employer_postal_code',\n",
    "    'NBR_WORKERS_REQUESTED':'nbr_workers_requested',\n",
    "    'NBR_WORKERS_CERTIFIED':'nbr_workers_certified',\n",
    "    'TOTAL_WORKERS_NEEDED':'nbr_workers_needed',\n",
    "    'TOTAL_WORKERS_H2A_REQUESTED':'nbr_workers_requested',\n",
    "    'TOTAL_WORKERS_H2A_CERTIFIED':'nbr_workers_certified',\n",
    "    'REQUESTED_START_DATE_OF_NEED':'requested_begin_date',\n",
    "    'REQUESTED_END_DATE_OF_NEED':'requested_end_date',\n",
    "    'CERTIFICATION_BEGIN_DATE':'certification_begin_date',\n",
    "    'CERTIFICATION_END_DATE':'certification_end_date',\n",
    "    'REQUESTED_BEGIN_DATE':'requested_begin_date',\n",
    "    'REQUESTED_END_DATE':'requested_end_date',\n",
    "    'EMPLOYMENT_BEGIN_DATE':'job_begin_date',\n",
    "    'EMPLOYMENT_END_DATE':'job_end_date',\n",
    "    'JOB_START_DATE':'job_begin_date',\n",
    "    'JOB_END_DATE':'job_end_date',\n",
    "    'BASIC_NUMBER_OF_HOURS':'number_of_hours',\n",
    "    'ANTICIPATED_NUMBER_OF_HOURS':'number_of_hours',\n",
    "    'BASIC_RATE_OF_PAY':'wage_rate',\n",
    "    'WAGE_OFFER':'wage_rate',\n",
    "    'BASIC_UNIT_OF_PAY':'wage_unit',\n",
    "    'PER':'wage_unit',\n",
    "    'ALIEN_WORK_CITY':'worksite_city',\n",
    "    'ALIEN_WORK_STATE':'worksite_state',\n",
    "    'WORKSITE_LOCATION_CITY':'worksite_city',\n",
    "    'WORKSITE_LOCATION_STATE':'worksite_state',\n",
    "    'WORKSITE_CITY':'worksite_city',\n",
    "    'WORKSITE_COUNTY':'worksite_county',\n",
    "    'WORKSITE_STATE':'worksite_state',\n",
    "    'WORKSITE_POSTAL_CODE':'worksite_zip',\n",
    "    'PRIMARY/SUB':'primary_sub',\n",
    "    'PRIMARY_SUB':'primary_sub',\n",
    "    'PRMARY/SUB':'primary_sub',\n",
    "    'ORGANIZATION_FLAG':'organization_flag',\n",
    "    'TYPE_OF_EMPLOYER_APPLICATION':'type_of_employer_application',\n",
    "    'H2A_LABOR_CONTRACTOR':'h2a_labor_contractor',\n",
    "    'AG_ASSN_OR_AGENCY_STATUS':'ag_association_or_agency',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_df = pd.DataFrame()\n",
    "for year, df in h2a_df_dict.items():\n",
    "    df = df.rename(columns = h2a_rename_dict)\n",
    "    df['fiscal_year'] = year\n",
    "    h2a_df = pd.concat([h2a_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip time, define consistent NAs, convert all entries to uppercase\n",
    "h2a_df = h2a_df.apply(lambda x: x.str.replace(' 00:00:00', ''))\n",
    "h2a_df = h2a_df.fillna(value='').apply(lambda x: x.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match FIPS codes for worksite locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the list of worksites we want to obtain county FIPS codes for\n",
    "h2a_worksite_locations = h2a_df[['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip']]\n",
    "h2a_worksite_locations = h2a_worksite_locations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to match as many worksites as possible with AddFIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by fixing some basic data entry errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some entries with state in the county column; fill in state name in state column if empty\n",
    "state_name_list = []\n",
    "state_abbr_list = []\n",
    "for x in us.states.STATES:\n",
    "    state_abbr_list.append(x.abbr.upper())\n",
    "    state_name_list.append(x.name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_worksite_locations.loc[(h2a_worksite_locations['city'] == 'PLANKINTON') & (h2a_worksite_locations['county'] == 'AURORA'), 'state'] = \"SD\"\n",
    "h2a_worksite_locations.loc[(h2a_worksite_locations['city'] == 'SOUTH LAKE TAHOE') & (h2a_worksite_locations['county'] == 'CALIFORNIA'), 'state'] = \"CA\"\n",
    "h2a_worksite_locations.loc[(h2a_worksite_locations['city'] == 'PARMA') & (h2a_worksite_locations['county'] == 'IDAHO'), 'state'] = \"ID\"\n",
    "h2a_worksite_locations.loc[(h2a_worksite_locations['city'] == 'IOWA') & (h2a_worksite_locations['county'] == 'LOUISIANA'), 'state'] = \"LA\"\n",
    "h2a_worksite_locations.loc[(h2a_worksite_locations['city'] == 'BRIGGSDALE') & (h2a_worksite_locations['county'] == 'WELD'), 'state'] = \"CO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these are cities, some are multiple counties smushed together\n",
    "h2a_worksite_locations['city'] = h2a_worksite_locations['worksite_city']\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['worksite_county']\n",
    "h2a_worksite_locations['state'] = h2a_worksite_locations['worksite_state']\n",
    "h2a_worksite_locations['zip'] = h2a_worksite_locations['worksite_zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split entries with AND, &, / for multiple counties, by adding ',' separators\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' AND ', ',')\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' & ', ',')\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace('/', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode\n",
    "h2a_worksite_locations['id'] = h2a_worksite_locations.reset_index().index.copy().astype('str')\n",
    "h2a_worksite_locations['county_list'] = h2a_worksite_locations['county'].str.split(',')\n",
    "h2a_worksite_locations = h2a_worksite_locations.explode('county_list')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "h2a_worksite_locations['county_list'] = h2a_worksite_locations['county_list'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip suffixes from names\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' COUNTY', '')\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' COUNTIES', '')\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' PARISH', '')\n",
    "h2a_worksite_locations['county'] = h2a_worksite_locations['county'].str.replace(' PARRISH', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix common typos\n",
    "# These are common typos\n",
    "h2a_worksite_locations['county_list'] = h2a_worksite_locations['county_list'].str.replace(\"ST \", \"ST. \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"ST\\.\\w\", \"ST. \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"NORTH\\. \", \"NORTH \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"SOUTH\\. \", \"SOUTH \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"EAST\\. \", \"EAST \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"WEST\\. \", \"WEST \", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"BATON ROGUE\", \"BATON ROUGE\", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"JEFF DAVIS\", \"JEFFERSON DAVIS\", regex=True)\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['state'] == \"LA\", 'county_list'] = h2a_worksite_locations[h2a_worksite_locations['state'] == \"LA\"]['county_list'].str.replace(r\"IBERIAL\", \"IBERIA\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split some entries with multiple counties by hand\n",
    "# These are entries with multiple counties where simple replacement of separators with ',' for explosion doesn't work\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'HARRISON & BOURBON COUNTIES', 'county'] = 'HARRISON,BOURBON'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'STAMPING GROUND SCOTT COUNTY', 'county'] = 'SCOTT'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'HENRY & UNION COUNTY', 'county'] = 'HENRY,UNION'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'SILVER BOW AND MADISON', 'county'] = 'SILVER BOW,MADISON'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'CANDLER BULLOCH & EVANS COUNTIES', 'county'] = 'CANDLER,BULLOCH,EVANS'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'SAMPSON AND JOHNSTON COUNTIES', 'county'] = 'SAMPSON,JOHNSTON'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'LINCOLN AND BAYFIELD COUNTIES', 'county'] = 'LINCOLN,BAYFIELD'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'ALLEN & MONROE COUNTIES', 'county'] = 'ALLEN,MONROE'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'OWEN & HENRY COUNTIES', 'county'] = 'OWEN,HENRY'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'UPTON/MAGNOLIA HART COUNTY', 'county'] = 'UPTON,MAGNOLIA,HART'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'WARREN & SIMPSON COUNTY', 'county'] = 'WARREN,SIMPSON'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'CASEY & BOYLE COUNTIES', 'county'] = 'CASEY,BOYLE'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'MONTGOMERY & HALIFAX COUNTIES', 'county'] = 'MONTOGOMERY,HALIFAX'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'COUNTIES: RISING SUN DILLISBORO DEARBORN', 'county'] = 'RISING SUN,DILLSBORO,DEARBORN'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'GEORGE AND RANKIN COUNTIES', 'county'] = 'GEORGE,RANKIN'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'MISSAUKEE WEXFORD OSCEOLA & ANTRIM COUNTIES', 'county'] = 'MISSAUKEE,WEXFORD,OSCEOLA,ANTRIM'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'WASHAKIE BIG HORN JOHNSON COUNTY', 'county'] = 'WASHAKIE,BIG HORN,JOHNSON'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'SOMERSET/BALD MOUNTAIN-UNORGANIZED TS', 'county'] = 'SOMERSET,BALD MOUNTAIN'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'MAHLEUR AND HARNEY COUNTIES', 'county'] = 'MAHLEUR,HARNEY'\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county'] == 'FRANKLIN & SOMERSET', 'county'] = 'FRANKLIN,SOMERSET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some entries with state names in the county column should have the county blanked out\n",
    "# Some entries have USA or U.S.A in the county column as well\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county_list'] == h2a_worksite_locations['state'], 'county_list'] = \"\"\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county_list'].isin(state_abbr_list), 'county_list'] = \"\"\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county_list'].isin(state_name_list), 'county_list'] = \"\"\n",
    "\n",
    "usa_list = ['USA', 'U.S.A', 'U.S.A.', 'UNITED STATES', 'UNITED STATES OF AMERICA']\n",
    "h2a_worksite_locations.loc[h2a_worksite_locations['county_list'].isin(usa_list), 'county_list'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use addfips package to get FIPS codes for each state-county pair\n",
    "af = addfips.AddFIPS()\n",
    "h2a_worksite_locations['fips_from_addfips'] = h2a_worksite_locations.apply(lambda x: af.get_county_fips(x['county_list'], state=x['state']), axis=1)\n",
    "h2a_worksite_locations = h2a_worksite_locations.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_matched = h2a_worksite_locations[h2a_worksite_locations['fips_from_addfips']!=''].copy()\n",
    "\n",
    "# For unmatched, see if there are issues we can fix\n",
    "h2a_unmatched = h2a_worksite_locations[h2a_worksite_locations['fips_from_addfips']==''].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now match the unmatched using Census county names, place names, and ZCTA (ZIP) codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are mistakes in the ZIP code\n",
    "h2a_unmatched.loc[:, 'zip'] = h2a_unmatched['zip'].str.pad(width=5, side='left', fillchar='0')\n",
    "h2a_unmatched.loc[:, 'zip'] = h2a_unmatched['zip'].str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with those with county information first\n",
    "h2a_unmatched_counties = h2a_unmatched[(h2a_unmatched['county_list']!='') & (h2a_unmatched['state']!='')]\n",
    "h2a_unmatched_counties = h2a_unmatched_counties.sort_values(['state', 'county_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fuzzy string matching to check for obvious typos in county names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for fuzzy string matching\n",
    "def fuzz_search(census_df, census_col, state_to_search, name_to_match):\n",
    "\n",
    "    def fuzz_match(x, y):\n",
    "        return rapidfuzz.fuzz.partial_ratio_alignment(x, y).score\n",
    "    \n",
    "    state_df = census_df[census_df['STATE'] == state_to_search].copy()\n",
    "    state_df['score'] = state_df[census_col].apply(lambda x: fuzz_match(x, name_to_match))\n",
    "    \n",
    "    state_df = state_df.sort_values('score')\n",
    "    \n",
    "    max_score_row = state_df[state_df['score'] == state_df['score'].max()].reset_index()\n",
    "\n",
    "    # Best match\n",
    "    if len(max_score_row) >= 1:\n",
    "        fips = str(max_score_row['fips'][0])\n",
    "        score = str(max_score_row['score'][0])\n",
    "        census_name = (max_score_row[census_col][0])\n",
    "        return(fips, score, census_name)\n",
    "    else:\n",
    "        return('', '', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matches and match score\n",
    "census_df = census_county\n",
    "census_col = 'COUNTYNAME'\n",
    "fuzzy_result_df = h2a_unmatched_counties.apply(lambda x: fuzz_search(census_df, census_col, x.state, x.county_list), axis=1, result_type='expand')\n",
    "fuzzy_result_df = fuzzy_result_df.rename(columns = {0:'fips_from_county', 1:'score_from_county', 2:'census_name_county'})\n",
    "fuzzy_result_df['score_from_county'] = pd.to_numeric(fuzzy_result_df['score_from_county'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears 80 is a good cutoff\n",
    "fuzzy_result_df.loc[fuzzy_result_df['score_from_county'] < 80, ['fips_from_county']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine match list back in\n",
    "h2a_unmatched_counties = pd.concat([h2a_unmatched_counties, fuzzy_result_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use fuzzy string matching for city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matches and match score using city instead\n",
    "census_df = census_placebycounty\n",
    "census_col = 'PLACENAME'\n",
    "fuzzy_result_df = h2a_unmatched_counties.apply(lambda x: fuzz_search(census_df, census_col, x.state, x.city), axis=1, result_type='expand')\n",
    "fuzzy_result_df = fuzzy_result_df.rename(columns = {0:'fips_from_city', 1:'score_from_city', 2:'census_name_city'})\n",
    "fuzzy_result_df['score_from_city'] = pd.to_numeric(fuzzy_result_df['score_from_city'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears 90 is a good cutoff\n",
    "fuzzy_result_df.loc[fuzzy_result_df['score_from_city'] < 90, ['fips_from_city']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine match list back in\n",
    "h2a_unmatched_counties = pd.concat([h2a_unmatched_counties, fuzzy_result_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also match using ZIP codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_zip_agg = census_zip_agg.rename(columns = {'GEOID_ZCTA5_20':'zip', 'fips':'fips_from_zip'})\n",
    "h2a_unmatched_counties = h2a_unmatched_counties.merge(census_zip_agg, how='left', on=['zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New England has to be mapped separately as they put place names in their county column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obvious that New England states have to be handled separately, as they use town names as counties; rematch these again using county entry with census city/place names\n",
    "new_england_states = ['CT', 'ME', 'MA', 'NH', 'RI', 'VT']\n",
    "\n",
    "# Get matches and match score using city instead\n",
    "census_df = census_place_agg\n",
    "census_col = 'PLACENAME'\n",
    "fuzzy_result_df = h2a_unmatched_counties.apply(lambda x: fuzz_search(census_df, census_col, x.state, x.county_list), axis=1, result_type='expand')\n",
    "fuzzy_result_df = fuzzy_result_df.rename(columns = {0:'fips_from_city_ne', 1:'score_from_city_ne', 2:'census_name_city_ne'})\n",
    "fuzzy_result_df['score_from_city_ne'] = pd.to_numeric(fuzzy_result_df['score_from_city_ne'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine match list back in\n",
    "h2a_unmatched_counties = pd.concat([h2a_unmatched_counties, fuzzy_result_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different states have different cutoffs\n",
    "# CT - 90\n",
    "# MA - 95\n",
    "# ME - 80\n",
    "# NH - 83\n",
    "# RI - 99\n",
    "# VT - 89\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'CT') & (h2a_unmatched_counties['score_from_city_ne'] < 90), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'MA') & (h2a_unmatched_counties['score_from_city_ne'] < 95), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'ME') & (h2a_unmatched_counties['score_from_city_ne'] < 80), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'NH') & (h2a_unmatched_counties['score_from_city_ne'] < 83), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'RI') & (h2a_unmatched_counties['score_from_city_ne'] < 99), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'VT') & (h2a_unmatched_counties['score_from_city_ne'] < 89), ['fips_from_city_ne']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some mistakes in the New England matches\n",
    "# HAMPTON - NORTHAMPTON CITY in MA\n",
    "# STOW - WILLIAMSTOWN CDP in MA\n",
    "# SO - SOUTH PARIS CDP in ME\n",
    "# CHESTER - MANCHESTER CITY in NH\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'MA') & (h2a_unmatched_counties['city'] == 'HAMPTON') & (h2a_unmatched_counties['census_name_city_ne'] == 'NORTHAMPTON CITY'), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'MA') & (h2a_unmatched_counties['city'] == 'STOW') & (h2a_unmatched_counties['census_name_city_ne'] == 'WILLIAMSTOWN CDP'), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'ME') & (h2a_unmatched_counties['city'] == 'SO') & (h2a_unmatched_counties['census_name_city_ne'] == 'SOUTH PARIS CDP'), ['fips_from_city_ne']] = ''\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['state'] == 'NH') & (h2a_unmatched_counties['city'] == 'CHESTER') & (h2a_unmatched_counties['census_name_city_ne'] == 'MANCHESTER CITY'), ['fips_from_city_ne']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix New England FIPS codes\n",
    "h2a_unmatched_counties.loc[(h2a_unmatched_counties['worksite_state'].isin(new_england_states)) & (h2a_unmatched_counties['fips_from_city'].isna() | h2a_unmatched_counties['fips_from_city'] == ''), 'fips_from_city'] = h2a_unmatched_counties['fips_from_city_ne']\n",
    "h2a_unmatched_counties = h2a_unmatched_counties.drop(columns = ['fips_from_city_ne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For entries without county information, merge just on city and ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_cities = h2a_unmatched[(h2a_unmatched['county_list']=='') & (h2a_unmatched['state']!='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matches and match score using city instead\n",
    "census_df = census_place_agg\n",
    "census_col = 'PLACENAME'\n",
    "fuzzy_result_df = h2a_unmatched_cities.apply(lambda x: fuzz_search(census_df, census_col, x.state, x.city), axis=1, result_type='expand')\n",
    "fuzzy_result_df = fuzzy_result_df.rename(columns = {0:'fips_from_city', 1:'score_from_city', 2:'census_name_city'})\n",
    "fuzzy_result_df['score_from_city'] = pd.to_numeric(fuzzy_result_df['score_from_city'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears 85 is a good cutoff\n",
    "fuzzy_result_df.loc[fuzzy_result_df['score_from_city'] < 85, ['fips_from_city']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine match list back in\n",
    "h2a_unmatched_cities = pd.concat([h2a_unmatched_cities, fuzzy_result_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match using ZIP code\n",
    "h2a_unmatched_cities = h2a_unmatched_cities.merge(census_zip_agg, how='left', on=['zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to choose which matched FIPS codes to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only needed variables for this\n",
    "h2a_unmatched_counties = h2a_unmatched_counties[['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip', 'zip', 'id', 'fips_from_county', 'fips_from_city', 'fips_from_zip']]\n",
    "h2a_unmatched_cities = h2a_unmatched_cities[['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip', 'zip', 'id', 'fips_from_city', 'fips_from_zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_with_fips = pd.concat([h2a_unmatched_cities, h2a_unmatched_counties], axis=0)\n",
    "\n",
    "# Convert NaNs into blank strings\n",
    "h2a_unmatched_with_fips = h2a_unmatched_with_fips.fillna(value = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_with_fips[(h2a_unmatched_with_fips['fips_from_zip']=='') & (h2a_unmatched_with_fips['zip']!='')].to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function with logic for choosing FIPS\n",
    "def fips_choice(county_fips, zip_fips, city_fips):\n",
    "    if (zip_fips != ''):\n",
    "        return(zip_fips)\n",
    "    \n",
    "    if (county_fips != ''):\n",
    "        return(county_fips)\n",
    "    \n",
    "    if (city_fips != ''):\n",
    "        return(city_fips)\n",
    "    \n",
    "    else:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose fips\n",
    "h2a_unmatched_with_fips['fips_from_census'] = h2a_unmatched_with_fips.apply(lambda x: fips_choice(x.fips_from_county, x.fips_from_zip, x.fips_from_city), axis=1)\n",
    "h2a_unmatched_with_fips = h2a_unmatched_with_fips[['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip', 'id', 'fips_from_census']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine back into original H-2A data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All worksite locations in the original data, but exploded\n",
    "h2a_worksite_locations_all = h2a_worksite_locations.merge(h2a_unmatched_with_fips, how='left', on=['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalized FIPS codes\n",
    "h2a_worksite_locations_all = h2a_worksite_locations_all.fillna(value = '')\n",
    "h2a_worksite_locations_all['fips'] = h2a_worksite_locations_all['fips_from_addfips']\n",
    "h2a_worksite_locations_all.loc[h2a_worksite_locations_all['fips']=='', 'fips'] = h2a_worksite_locations_all['fips_from_census']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate back into original worksite entries using original ID\n",
    "h2a_worksite_locations_agg = h2a_worksite_locations_all.groupby(['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip', 'id']).agg({'fips': lambda x: ','.join(x)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge fips back into original H-2a file\n",
    "h2a_df_with_fips = h2a_df.merge(h2a_worksite_locations_agg, how = 'left', on = ['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining locations, find county using Google's Places API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by finding the Place ID for each location using Find Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_census = h2a_worksite_locations_agg[h2a_worksite_locations_agg['fips'] == ''][['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these are counties, tag them\n",
    "h2a_unmatched_census['place_name'] = h2a_unmatched_census['worksite_city']\n",
    "h2a_unmatched_census['are_counties'] = h2a_unmatched_census['place_name'].str.contains(pat=r\" COUNTY| COUNTIES| COUNTIE| COUNTRY|COUNTIES: | CO\\.\", regex=True)\n",
    "h2a_unmatched_census['place_name'] = h2a_unmatched_census['place_name'].str.replace(pat=r\" COUNTY| COUNTIES| COUNTIE| COUNTRY|COUNTIES: | CO\\.\", regex=True, repl='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_census['place_name'] = h2a_unmatched_census['place_name'].str.replace(pat=r\"\\(SEE ATTACH.*\\)\", regex=True, repl='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'WASHAKIE, BIG HORN JOHNSON COUNTY', 'place_name'] = 'WASHAKIE,BIG HORN,JOHNSON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == '1) WENDEN 2)TONOPAH  3) DATELAND', 'place_name'] = 'WENDEN,TONOPAH,DATELAND'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == '1.- TONOPAH                           2.- DATELAND', 'place_name'] = 'TONOPAH,DATELAND'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'BRANCH & ST. JOSEPH COS. IN MI & LAGRANGE CO. IN', 'place_name'] = 'BRANCH COUNTY,ST. JOSEPH'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTE  CT. HTS.', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTE CT, HS', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTE CT. HS.', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTE CT.HS', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTE CT.HS.', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'CHARLOTTEE CT.HS.', 'place_name'] = 'CHARLOTTE COURT HOUSE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'DUMAS AND AMARILLO  79029 & 79120', 'place_name'] = 'DUMAS,AMARILLO'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'EDISON, NE 68932', 'place_name'] = 'EDISON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'EMPLOYER OWNED AND OPERATED', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'EDISON, NE 68932', 'place_name'] = 'EDISON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'ESSEX JCT.', 'place_name'] = 'ESSEX JUNCTION'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'ESSEX, JCT.', 'place_name'] = 'ESSEX JUNCTION'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'FANNETTSBURG, PA 17221', 'place_name'] = 'FANNETTSBURG'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'FAYETTE C. & BOURBON CO.', 'place_name'] = 'FAYETTE,BOURBON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'HAWESVILLE, KY AND HAWESVILLE', 'place_name'] = 'HAWESVILLE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'HILLSVILLE SEE ATTACHMENT # 1', 'place_name'] = 'HILLSVILLE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'LEBANON, NJ 08833', 'place_name'] = 'LEBANON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'MT, PLEASANT', 'place_name'] = 'MT. PLEASANT'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'NEAREST TOWN IS FORT KENT MAINE', 'place_name'] = 'FORT KENT'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'ODELL, TEXAS 79247', 'place_name'] = 'ODELL'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'PITTSBURG, ATKINSON GILMANTON ACADEMY', 'place_name'] = 'ATKINSON GILMANTON ACADEMY'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'PITTSBURG, ATKINSON GILMANTON ACADEMY GRANT', 'place_name'] = 'ATKINSON GILMANTON ACADEMY'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'PITTSBURG, ATKINSON, GILMANTON ACADEMY', 'place_name'] = 'ATKINSON GILMANTON ACADEMY'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'PLEASE SEE 7A. BELOW.', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'RIPLEY, TN.', 'place_name'] = 'RIPLEY'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'SEE ADDENDUM', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'SEE ATTACHMENT', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'SEE ATTACHMENT # 1', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'SEE ATTACHMENT #1', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'STARTS IN HAYS, KS', 'place_name'] = 'HAYS'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'T13R14, T5R11, ESTCOURT', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'T8R12,T7R13,T8R13,T9R13,T7R14,T8R14,T5R15,T6R15,T7', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'T911,T8R12,T7R13,T7R14,T8R14,T5R15,T6R15,T7R15', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'T9R11,T8R12,T7R13,T8R13,T9R13,T7R14,T8R14,T5R15,T6', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'TOWNSHIP', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'TOWNSHIP T15R15', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'].str.contains(pat=r\"UNORGANIZED TOWN\", regex=True), 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'UNORANIZED TOWNSHIPS AROUND', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'UNORGANIZED TOWNSHIPS AROUND THE CLAYTON LAKE AREA', 'place_name'] = 'CLAYTON LAKE'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'UNORGANIZED TOWNSHIPS: NEAREST TOWN IS JACKSON MAI', 'place_name'] = 'JACKSON'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'UNORGANIZED TOWNSHIPS; AROUND EUSTIS', 'place_name'] = 'EUSTIS'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'VARIOUS', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'VARIOUS IN WESTERN', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'VARIOUS UNORGAINIZED TOWNSHIPS', 'place_name'] = ''\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'VARIOUS, BEGINNING IN STRATFORD', 'place_name'] = 'STRATFORD'\n",
    "h2a_unmatched_census.loc[h2a_unmatched_census['place_name'] == 'WESTON, TX', 'place_name'] = 'WESTON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2a_unmatched_census['place_list'] = h2a_unmatched_census['place_name'].str.split(pat = r\" AND | & |,|/\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add county suffix to entries that are county names\n",
    "def add_county_suffix(is_county, name):\n",
    "    if is_county == True:\n",
    "        if isinstance(name, str):\n",
    "            name = name + ' COUNTY'\n",
    "            return(name)\n",
    "        else:\n",
    "            name_list = [x + ' COUNTY' for x in name]\n",
    "            return(name_list)\n",
    "    else:\n",
    "        return(name)\n",
    "    \n",
    "h2a_unmatched_census['place_list'] =  h2a_unmatched_census.apply(lambda x: add_county_suffix(x.are_counties, x.place_list), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_dict = {}\n",
    "for x in us.states.STATES:\n",
    "    state_name_dict[x.abbr] = x.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have to search for rows without a place name or state name\n",
    "h2a_unmatched_census = h2a_unmatched_census[h2a_unmatched_census['place_name']!='']\n",
    "h2a_unmatched_census['state_name'] = h2a_unmatched_census['worksite_state'].map(state_name_dict)\n",
    "h2a_unmatched_census = h2a_unmatched_census[~h2a_unmatched_census['state_name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode for rows with multiple places\n",
    "h2a_unmatched_census = h2a_unmatched_census.explode(column = 'place_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ID for each row to link with API request responses\n",
    "h2a_unmatched_census['id'] = h2a_unmatched_census.reset_index().index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split API calls into chunks of 100\n",
    "h2a_unmatched_census['chunk'] = h2a_unmatched_census['id'].astype(int)//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google maps API key from my account\n",
    "# Import API key stored in text file\n",
    "with open(\"../tools/google_places_api_key.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "api_key = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base url to call Find Place API\n",
    "# base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?\"\n",
    "\n",
    "# for c in range(0, 14):\n",
    "#     h2a_chunk = h2a_unmatched_census[h2a_unmatched_census['chunk'] == c]\n",
    "\n",
    "#     # Dict to store API responses\n",
    "#     api_placeid_dict = {}\n",
    "\n",
    "#     for ind in range(0, len(h2a_chunk)):\n",
    "#         row = h2a_chunk.iloc[ind]\n",
    "#         id = row['id']\n",
    "#         state_name = row['state_name']\n",
    "#         place_name = row['place_list']\n",
    "#         name_to_search = place_name + ', ' + state_name\n",
    "\n",
    "#         print(id, name_to_search)\n",
    "\n",
    "#         # Create API request\n",
    "#         # URL'ed location name we want to search\n",
    "#         input = urllib.parse.quote(name_to_search) # Encode place name as URL string\n",
    "#         request_url = base_url + \"input=\" + input + \"&inputtype=textquery\" + \"&fields=place_id\" + \"&key=\" + api_key\n",
    "\n",
    "#         payload = {}\n",
    "#         headers = {}\n",
    "\n",
    "#         # Sleep one second between each API call\n",
    "#         time.sleep(1)\n",
    "\n",
    "#         # Make API call\n",
    "#         response = requests.request(\"GET\", request_url, headers=headers, data=payload)\n",
    "#         response_json = response.json()\n",
    "        \n",
    "#         # If API call is successful, then place response result into dict\n",
    "#         if response_json['status']=='OK':\n",
    "#             print('Successful')\n",
    "#             api_placeid_dict[id] = response_json\n",
    "#         else:\n",
    "#             # If API call is unsuccessful, then wait 5 seconds and retry\n",
    "#             print('NOT successful, retrying')\n",
    "#             time.sleep(5)\n",
    "#             response = requests.request(\"GET\", request_url, headers=headers, data=payload)\n",
    "#             response_json = response.json()\n",
    "\n",
    "#             if response_json['status']=='OK':\n",
    "#                 print('Retry successful')\n",
    "#                 api_placeid_dict[id] = response_json\n",
    "#             else:\n",
    "#                 error_type = response_json['status']\n",
    "#                 print('Retry unsuccessful, error: ' + error_type)\n",
    "\n",
    "#     # Save API request results as JSON\n",
    "#     with open(f'json/placeid_api_request_result_chunk_{c}.json', 'w') as f:\n",
    "#         json.dump(api_placeid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the Place ID to find the county name of each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON of API responses and put into DataFrame\n",
    "api_placeid_dict = {}\n",
    "for c in range(0, 14):\n",
    "    with open(f'json/placeid_api_request_result_chunk_{c}.json', 'r') as infile:\n",
    "        api_dict = json.load(infile)\n",
    "\n",
    "    api_placeid_dict = api_placeid_dict | api_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put place IDs into DataFrame\n",
    "api_placeid_df = pd.DataFrame(columns=['id', 'placeid'])\n",
    "\n",
    "for id, response in api_placeid_dict.items():\n",
    "    number_of_candidates = len(response['candidates'])\n",
    "    for response_ind in range(0, number_of_candidates):\n",
    "        placeid = response['candidates'][response_ind]['place_id']\n",
    "        api_placeid_df.loc[len(api_placeid_df)] = [id, placeid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split API calls into chunks of 100\n",
    "api_placeid_df['chunk'] = api_placeid_df['id'].astype(int)//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Place details API to get county names\n",
    "# base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# for c in range(0, 16):\n",
    "#     api_placeid_chunk = api_placeid_df[api_placeid_df['chunk'] == c]\n",
    "#     api_place_details_dict = {}\n",
    "\n",
    "#     # Iterate over each place ID\n",
    "#     for index, row in api_placeid_chunk.iterrows():\n",
    "#         print(row['id'], row['placeid'])\n",
    "\n",
    "#         # Create API request\n",
    "#         input = row['placeid']\n",
    "#         request_url = base_url + \"place_id=\" + input + \"&key=\" + api_key\n",
    "\n",
    "#         payload = {}\n",
    "#         headers = {}\n",
    "\n",
    "#         response = requests.request(\"GET\", request_url, headers=headers, data=payload)\n",
    "#         response_json = response.json()\n",
    "\n",
    "#         # If API call is successful, then place response result into dict\n",
    "#         if response_json['status']=='OK':\n",
    "#             print('Successful')\n",
    "#             api_place_details_dict[input] = response_json\n",
    "#         else:\n",
    "#             # If API call is unsuccessful, then wait 5 seconds and retry\n",
    "#             print('NOT successful, retrying')\n",
    "#             time.sleep(5)\n",
    "#             response = requests.request(\"GET\", request_url, headers=headers, data=payload)\n",
    "#             response_json = response.json()\n",
    "\n",
    "#             if response_json['status']=='OK':\n",
    "#                 print('Retry successful')\n",
    "#                 api_place_details_dict[input] = response_json\n",
    "#             else:\n",
    "#                 error_type = response_json['status']\n",
    "#                 print('Retry unsuccessful, error: ' + error_type)\n",
    "\n",
    "#     # Save API request results as JSON\n",
    "#     with open(f'json/place_details_api_request_result_chunk_{c}.json', 'w') as f:\n",
    "#         json.dump(api_place_details_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON of API responses and put into DataFrame\n",
    "api_place_details_dict = {}\n",
    "for c in range(0, 16):\n",
    "    with open(f'json/place_details_api_request_result_chunk_{c}.json', 'r') as infile:\n",
    "        api_dict = json.load(infile)\n",
    "\n",
    "    api_place_details_dict = api_place_details_dict | api_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store county name from place details into dictionary (store state names too as there may be incorrect states)\n",
    "county_name_dict = {}\n",
    "state_name_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information we want from API response\n",
    "for placeid, response in api_place_details_dict.items():\n",
    "    n_responses = len(response['results'])\n",
    "\n",
    "    for response_ind in range(0, n_responses):\n",
    "        individual_response = response['results'][response_ind]\n",
    "        response_address_components_list = individual_response['address_components']\n",
    "        n_components = len(response_address_components_list)\n",
    "\n",
    "        for component_ind in range(0, n_components):\n",
    "            component_dict = response_address_components_list[component_ind]\n",
    "            component_type =  component_dict['types'][0]\n",
    "\n",
    "            if component_type == 'administrative_area_level_2':\n",
    "                county_name = component_dict['long_name']\n",
    "                county_name_dict[placeid] = county_name\n",
    "            \n",
    "            if component_type == 'administrative_area_level_1':\n",
    "                state_name = component_dict['long_name']\n",
    "                state_name_dict[placeid] = state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add county and state name columns to Place ID\n",
    "api_placeid_df['county_name_api'] = api_placeid_df['placeid'].map(county_name_dict)\n",
    "api_placeid_df['state_name_api'] = api_placeid_df['placeid'].map(state_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these multiple responses per place name are in the same county, so we can collapse those\n",
    "api_placeid_df = api_placeid_df.drop_duplicates(subset = ['id', 'county_name_api', 'state_name_api'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the remainder, manually resolve\n",
    "api_placeid_df = api_placeid_df.merge(h2a_unmatched_census[['place_list', 'state_name', 'id']], how = 'left', on = ['id'])\n",
    "multiple_response = api_placeid_df[api_placeid_df.duplicated(subset=['id'], keep=False)]\n",
    "multiple_response.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caddo, Texas is in Stephens County\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == '33 CADDO') & (api_placeid_df['state_name'] == 'Texas'), 'county_name_api'] = 'Stephens County'\n",
    "\n",
    "# Alice, Tennessee is ambiguous\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'ALICE') & (api_placeid_df['state_name'] == 'Tennessee'), 'county_name_api'] = None\n",
    "\n",
    "# Box 78, Kansas?\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'BOX 78') & (api_placeid_df['state_name'] == 'Kansas'), 'county_name_api'] = None\n",
    "\n",
    "# Britton, South Dakota is in Marshall County\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'BRITTON') & (api_placeid_df['state_name'] == 'North Dakota'), 'county_name_api'] = 'Marshall County'\n",
    "\n",
    "# There is no Casa Grande in Arkansas\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'CASA GRANDE') & (api_placeid_df['state_name'] == 'Arkansas'), 'county_name_api'] = None\n",
    "\n",
    "# There is no Clark in North Dakota\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'CLARK') & (api_placeid_df['state_name'] == 'North Dakota'), 'county_name_api'] = None\n",
    "\n",
    "# There is no Cothertown in Tennessee\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'COTHERTOWN') & (api_placeid_df['state_name'] == 'Tennessee'), 'county_name_api'] = None\n",
    "\n",
    "# There is no Craig in Wyoming\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'CRAIG') & (api_placeid_df['state_name'] == 'Wyoming'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == ' COUNTY') & (api_placeid_df['state_name'] == 'South Carolina'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'GLADSTONE') & (api_placeid_df['state_name'] == 'South Dakota'), 'county_name_api'] = None\n",
    "\n",
    "# Ambiguous\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'HOLLIS') & (api_placeid_df['state_name'] == 'Massachusetts'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'IDAHO COUNTY') & (api_placeid_df['state_name'] == 'Nevada'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'LONE TREE') & (api_placeid_df['state_name'] == 'Michigan'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'MACK (MAIL)') & (api_placeid_df['state_name'] == 'Colorado'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'MACK(MAIL)') & (api_placeid_df['state_name'] == 'Colorado'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'MAMOIA') & (api_placeid_df['state_name'] == 'Louisiana'), 'county_name_api'] = 'Evangeline Parish'\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'MANNNING') & (api_placeid_df['state_name'] == 'North Carolina'), 'county_name_api'] = 'Nash County'\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'MAURICECHURCH POINT') & (api_placeid_df['state_name'] == 'Louisiana'), 'county_name_api'] = 'Acadia Parish, Vermilion Parish'\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'NORTH SPRING VALLEY') & (api_placeid_df['state_name'] == 'Utah'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'PARKERS PRAIRIE') & (api_placeid_df['state_name'] == 'Missouri'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'PORTON') & (api_placeid_df['state_name'] == 'Arizona'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'ROYNE') & (api_placeid_df['state_name'] == 'Louisiana'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'SAVERY') & (api_placeid_df['state_name'] == 'Colorado'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'STRATFORD') & (api_placeid_df['state_name'] == 'North Dakota'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'THREE RIVERS') & (api_placeid_df['state_name'] == 'Florida'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'UNORGNAIZED TOWNSHIPS: AROUND') & (api_placeid_df['state_name'] == 'Maine'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'VASS') & (api_placeid_df['state_name'] == 'Tennessee'), 'county_name_api'] = None\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'WLIESBURG') & (api_placeid_df['state_name'] == 'Virginia'), 'county_name_api'] = 'Charlotte County'\n",
    "\n",
    "api_placeid_df.loc[(api_placeid_df['place_list'] == 'WOLCOTT') & (api_placeid_df['state_name'] == 'Idaho'), 'county_name_api'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recollapse after fixing\n",
    "api_placeid_df = api_placeid_df.drop_duplicates(subset = ['id', 'county_name_api', 'state_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAURICECHURCH POINT, Louisiana is actually 2 cities\n",
    "extra_row = api_placeid_df[api_placeid_df['place_list'] == 'MAURICECHURCH POINT'].copy()\n",
    "api_placeid_df.loc[api_placeid_df['place_list'] == 'MAURICECHURCH POINT', 'county_name_api'] = 'Acadia Parish'\n",
    "extra_row['county_name_api'] = 'Vermilion Parish'\n",
    "api_placeid_df = pd.concat([api_placeid_df, extra_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FIPS codes using addFIPS\n",
    "api_placeid_df = api_placeid_df[~api_placeid_df['county_name_api'].isna()].copy()\n",
    "api_placeid_df['fips_api'] = api_placeid_df.apply(lambda x: af.get_county_fips(x['county_name_api'], state=x['state_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop API results that don't match states\n",
    "api_placeid_df = api_placeid_df[api_placeid_df['state_name'] == api_placeid_df['state_name_api']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recollapse back into individual entries (some entries had multiple places per entry)\n",
    "h2a_api_df = h2a_unmatched_census.merge(api_placeid_df[['id', 'county_name_api', 'fips_api']], how = 'left', on = ['id'])\n",
    "h2a_api_df = h2a_api_df[~h2a_api_df['fips_api'].isna()].copy()\n",
    "h2a_api_df = h2a_api_df.groupby(['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip']).agg({'fips_api': lambda x: \",\".join(x)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FIPS from API to the H-2A entries based on worksites\n",
    "h2a_df_final = h2a_df_with_fips.merge(h2a_api_df, how='left', on=['worksite_city', 'worksite_county', 'worksite_state', 'worksite_zip'])\n",
    "h2a_df_final = h2a_df_final.fillna(value='')\n",
    "h2a_df_final.loc[h2a_df_final['fips'] == '', 'fips'] = h2a_df_final.loc[h2a_df_final['fips'] == '', 'fips_api']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export binary\n",
    "h2a_df_final = h2a_df_final.drop(columns = ['fips_api'])\n",
    "h2a_df_final.to_parquet(\"../binaries/h2a_with_fips.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      HR\n",
       "18                    MTH\n",
       "302                    WK\n",
       "614                   DAI\n",
       "5490                   BI\n",
       "10367                    \n",
       "40691               MONTH\n",
       "40692                HOUR\n",
       "40885    SELECT PAY RANGE\n",
       "41563           BI-WEEKLY\n",
       "41986                WEEK\n",
       "50466                YEAR\n",
       "Name: wage_unit, dtype: string"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2a_df_final['wage_unit'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>case_status</th>\n",
       "      <th>certification_begin_date</th>\n",
       "      <th>certification_end_date</th>\n",
       "      <th>employer_name</th>\n",
       "      <th>employer_city</th>\n",
       "      <th>employer_state</th>\n",
       "      <th>employer_postal_code</th>\n",
       "      <th>nbr_workers_certified</th>\n",
       "      <th>wage_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>worksite_zip</th>\n",
       "      <th>primary_sub</th>\n",
       "      <th>job_begin_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>worksite_county</th>\n",
       "      <th>type_of_employer_application</th>\n",
       "      <th>h2a_labor_contractor</th>\n",
       "      <th>nbr_workers_needed</th>\n",
       "      <th>id</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136645</th>\n",
       "      <td>H-300-21109-235767</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LA HACIENDA CITRUS, INC.</td>\n",
       "      <td>UTUADO</td>\n",
       "      <td>PR</td>\n",
       "      <td>611</td>\n",
       "      <td>4</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>611</td>\n",
       "      <td></td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>UTUADO</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>19494</td>\n",
       "      <td>72141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136646</th>\n",
       "      <td>H-300-21113-254532</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HACIENDA RAMIREZ, INC.</td>\n",
       "      <td>SAN SEBASTIAN</td>\n",
       "      <td>PR</td>\n",
       "      <td>685</td>\n",
       "      <td>6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>685</td>\n",
       "      <td></td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>SAN SEBASTIAN</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>19495</td>\n",
       "      <td>72131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136647</th>\n",
       "      <td>H-300-21137-318304</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HACIENDA LOS EUCALIPTOS, INC.</td>\n",
       "      <td>LARES</td>\n",
       "      <td>PR</td>\n",
       "      <td>669</td>\n",
       "      <td>12</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>669</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>LARES</td>\n",
       "      <td>JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>20</td>\n",
       "      <td>19496</td>\n",
       "      <td>72081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136648</th>\n",
       "      <td>H-300-21144-339364</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>YOMAR RAMOS-GONZALEZ</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "      <td>602</td>\n",
       "      <td>7</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>602</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>19497</td>\n",
       "      <td>72003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136649</th>\n",
       "      <td>H-300-21166-400271</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ROBERTO ATIENZA-FIGUEROA</td>\n",
       "      <td>JAYUYA</td>\n",
       "      <td>PR</td>\n",
       "      <td>664</td>\n",
       "      <td>6</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>664</td>\n",
       "      <td></td>\n",
       "      <td>2021-08-14</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>JAYUYA</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>19498</td>\n",
       "      <td>72073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152974</th>\n",
       "      <td>H-300-21250-569460</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TURNER FARMS NURSERY</td>\n",
       "      <td>WILMER</td>\n",
       "      <td>AL</td>\n",
       "      <td>36587</td>\n",
       "      <td>6</td>\n",
       "      <td>11.81</td>\n",
       "      <td>...</td>\n",
       "      <td>36587</td>\n",
       "      <td></td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>14459</td>\n",
       "      <td>01097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152975</th>\n",
       "      <td>H-300-21265-599271</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WESTERN RANGE ASSOCIATION</td>\n",
       "      <td>TWIN FALLS</td>\n",
       "      <td>ID</td>\n",
       "      <td>83301</td>\n",
       "      <td>5</td>\n",
       "      <td>1727.75</td>\n",
       "      <td>...</td>\n",
       "      <td>81403</td>\n",
       "      <td></td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>MONTROSE</td>\n",
       "      <td>ASSOCIATION - JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>10501</td>\n",
       "      <td>08085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152976</th>\n",
       "      <td>H-300-21265-599641</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WESTERN RANGE ASSOCIATION</td>\n",
       "      <td>TWIN FALLS</td>\n",
       "      <td>ID</td>\n",
       "      <td>83301</td>\n",
       "      <td>2</td>\n",
       "      <td>1727.75</td>\n",
       "      <td>...</td>\n",
       "      <td>84643</td>\n",
       "      <td></td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>SANPETE</td>\n",
       "      <td>ASSOCIATION - JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>21211</td>\n",
       "      <td>49039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152977</th>\n",
       "      <td>H-300-21265-600060</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WESTERN RANGE ASSOCIATION</td>\n",
       "      <td>TWIN FALLS</td>\n",
       "      <td>ID</td>\n",
       "      <td>83301</td>\n",
       "      <td>7</td>\n",
       "      <td>1727.75</td>\n",
       "      <td>...</td>\n",
       "      <td>84033</td>\n",
       "      <td></td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>SUMMIT</td>\n",
       "      <td>ASSOCIATION - JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>10414</td>\n",
       "      <td>49043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152978</th>\n",
       "      <td>H-300-21265-600379</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WESTERN RANGE ASSOCIATION</td>\n",
       "      <td>TWIN FALLS</td>\n",
       "      <td>ID</td>\n",
       "      <td>83301</td>\n",
       "      <td>8</td>\n",
       "      <td>1727.75</td>\n",
       "      <td>...</td>\n",
       "      <td>82009</td>\n",
       "      <td></td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>LARAMIE</td>\n",
       "      <td>ASSOCIATION - JOINT EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>10479</td>\n",
       "      <td>56021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16334 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               case_number                           case_status  \\\n",
       "136645  H-300-21109-235767  DETERMINATION ISSUED - CERTIFICATION   \n",
       "136646  H-300-21113-254532  DETERMINATION ISSUED - CERTIFICATION   \n",
       "136647  H-300-21137-318304  DETERMINATION ISSUED - CERTIFICATION   \n",
       "136648  H-300-21144-339364  DETERMINATION ISSUED - CERTIFICATION   \n",
       "136649  H-300-21166-400271  DETERMINATION ISSUED - CERTIFICATION   \n",
       "...                    ...                                   ...   \n",
       "152974  H-300-21250-569460  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152975  H-300-21265-599271  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152976  H-300-21265-599641  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152977  H-300-21265-600060  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152978  H-300-21265-600379  DETERMINATION ISSUED - CERTIFICATION   \n",
       "\n",
       "       certification_begin_date certification_end_date  \\\n",
       "136645                                                   \n",
       "136646                                                   \n",
       "136647                                                   \n",
       "136648                                                   \n",
       "136649                                                   \n",
       "...                         ...                    ...   \n",
       "152974                                                   \n",
       "152975                                                   \n",
       "152976                                                   \n",
       "152977                                                   \n",
       "152978                                                   \n",
       "\n",
       "                        employer_name  employer_city employer_state  \\\n",
       "136645       LA HACIENDA CITRUS, INC.         UTUADO             PR   \n",
       "136646         HACIENDA RAMIREZ, INC.  SAN SEBASTIAN             PR   \n",
       "136647  HACIENDA LOS EUCALIPTOS, INC.          LARES             PR   \n",
       "136648           YOMAR RAMOS-GONZALEZ         AGUADA             PR   \n",
       "136649       ROBERTO ATIENZA-FIGUEROA         JAYUYA             PR   \n",
       "...                               ...            ...            ...   \n",
       "152974           TURNER FARMS NURSERY         WILMER             AL   \n",
       "152975      WESTERN RANGE ASSOCIATION     TWIN FALLS             ID   \n",
       "152976      WESTERN RANGE ASSOCIATION     TWIN FALLS             ID   \n",
       "152977      WESTERN RANGE ASSOCIATION     TWIN FALLS             ID   \n",
       "152978      WESTERN RANGE ASSOCIATION     TWIN FALLS             ID   \n",
       "\n",
       "       employer_postal_code nbr_workers_certified wage_rate  ... worksite_zip  \\\n",
       "136645                  611                     4      7.25  ...          611   \n",
       "136646                  685                     6      7.25  ...          685   \n",
       "136647                  669                    12      7.25  ...          669   \n",
       "136648                  602                     7      7.25  ...          602   \n",
       "136649                  664                     6      7.25  ...          664   \n",
       "...                     ...                   ...       ...  ...          ...   \n",
       "152974                36587                     6     11.81  ...        36587   \n",
       "152975                83301                     5   1727.75  ...        81403   \n",
       "152976                83301                     2   1727.75  ...        84643   \n",
       "152977                83301                     7   1727.75  ...        84033   \n",
       "152978                83301                     8   1727.75  ...        82009   \n",
       "\n",
       "       primary_sub job_begin_date job_end_date worksite_county  \\\n",
       "136645                 2021-06-28   2022-04-15          UTUADO   \n",
       "136646                 2021-06-28   2022-04-15   SAN SEBASTIAN   \n",
       "136647                 2021-07-18   2022-05-17           LARES   \n",
       "136648                 2021-07-23   2022-05-22          AGUADA   \n",
       "136649                 2021-08-14   2022-06-13          JAYUYA   \n",
       "...            ...            ...          ...             ...   \n",
       "152974                 2021-11-01   2022-08-31          MOBILE   \n",
       "152975                 2021-12-01   2022-01-31        MONTROSE   \n",
       "152976                 2021-12-01   2022-02-28         SANPETE   \n",
       "152977                 2021-12-01   2022-04-30          SUMMIT   \n",
       "152978                 2021-12-01   2022-05-31         LARAMIE   \n",
       "\n",
       "        type_of_employer_application h2a_labor_contractor nbr_workers_needed  \\\n",
       "136645           INDIVIDUAL EMPLOYER                    N                  6   \n",
       "136646           INDIVIDUAL EMPLOYER                    N                 10   \n",
       "136647                JOINT EMPLOYER                    N                 20   \n",
       "136648                JOINT EMPLOYER                    N                 12   \n",
       "136649           INDIVIDUAL EMPLOYER                    N                 10   \n",
       "...                              ...                  ...                ...   \n",
       "152974           INDIVIDUAL EMPLOYER                    N                  6   \n",
       "152975  ASSOCIATION - JOINT EMPLOYER                    N                  5   \n",
       "152976  ASSOCIATION - JOINT EMPLOYER                    N                  2   \n",
       "152977  ASSOCIATION - JOINT EMPLOYER                    N                  7   \n",
       "152978  ASSOCIATION - JOINT EMPLOYER                    N                  8   \n",
       "\n",
       "           id   fips  \n",
       "136645  19494  72141  \n",
       "136646  19495  72131  \n",
       "136647  19496  72081  \n",
       "136648  19497  72003  \n",
       "136649  19498  72073  \n",
       "...       ...    ...  \n",
       "152974  14459  01097  \n",
       "152975  10501  08085  \n",
       "152976  21211  49039  \n",
       "152977  10414  49043  \n",
       "152978  10479  56021  \n",
       "\n",
       "[16334 rows x 29 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2a_df_final[h2a_df_final['fiscal_year'] == '2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>case_status</th>\n",
       "      <th>certification_begin_date</th>\n",
       "      <th>certification_end_date</th>\n",
       "      <th>employer_name</th>\n",
       "      <th>employer_city</th>\n",
       "      <th>employer_state</th>\n",
       "      <th>employer_postal_code</th>\n",
       "      <th>nbr_workers_certified</th>\n",
       "      <th>wage_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>worksite_zip</th>\n",
       "      <th>primary_sub</th>\n",
       "      <th>job_begin_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>worksite_county</th>\n",
       "      <th>type_of_employer_application</th>\n",
       "      <th>h2a_labor_contractor</th>\n",
       "      <th>nbr_workers_needed</th>\n",
       "      <th>id</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152979</th>\n",
       "      <td>H-300-21162-392244</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MIDWEST AG ELECTRIC INC.</td>\n",
       "      <td>ALBERT LEA</td>\n",
       "      <td>MN</td>\n",
       "      <td>56007</td>\n",
       "      <td>6</td>\n",
       "      <td>14.72</td>\n",
       "      <td>...</td>\n",
       "      <td>56039</td>\n",
       "      <td></td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>15092</td>\n",
       "      <td>27091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152980</th>\n",
       "      <td>H-300-21194-457735</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ALTENBURG CONSTRUCTION, INC.</td>\n",
       "      <td>LEWISVILLE</td>\n",
       "      <td>MN</td>\n",
       "      <td>56060</td>\n",
       "      <td>7</td>\n",
       "      <td>15.37</td>\n",
       "      <td>...</td>\n",
       "      <td>50436</td>\n",
       "      <td></td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>WINNEBAGO</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "      <td>21320</td>\n",
       "      <td>19189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152981</th>\n",
       "      <td>H-300-21221-510019</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PANCOST RANCH LLC</td>\n",
       "      <td>STONEHAM</td>\n",
       "      <td>CO</td>\n",
       "      <td>80754</td>\n",
       "      <td>1</td>\n",
       "      <td>1727.75</td>\n",
       "      <td>...</td>\n",
       "      <td>80754</td>\n",
       "      <td></td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>WELD</td>\n",
       "      <td>ASSOCIATION - AGENT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>17049</td>\n",
       "      <td>08123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152982</th>\n",
       "      <td>H-300-21223-516656</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LA ALIANZA, LP</td>\n",
       "      <td>NIPOMO</td>\n",
       "      <td>CA</td>\n",
       "      <td>93444</td>\n",
       "      <td>80</td>\n",
       "      <td>16.05</td>\n",
       "      <td>...</td>\n",
       "      <td>92233</td>\n",
       "      <td></td>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>IMPERIAL</td>\n",
       "      <td>JOINT EMPLOYER</td>\n",
       "      <td>Y</td>\n",
       "      <td>80</td>\n",
       "      <td>21321</td>\n",
       "      <td>06025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152983</th>\n",
       "      <td>H-300-21224-517089</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RC PACKING LLC</td>\n",
       "      <td>GONZALEZ</td>\n",
       "      <td>CA</td>\n",
       "      <td>93926</td>\n",
       "      <td>215</td>\n",
       "      <td>13.85</td>\n",
       "      <td>...</td>\n",
       "      <td>85365</td>\n",
       "      <td></td>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>YUMA</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>Y</td>\n",
       "      <td>215</td>\n",
       "      <td>10874</td>\n",
       "      <td>04027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172062</th>\n",
       "      <td>H-300-22262-479583</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A &amp; R FARMS, LLC</td>\n",
       "      <td>ALAPAHA</td>\n",
       "      <td>GA</td>\n",
       "      <td>31622</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>...</td>\n",
       "      <td>31622</td>\n",
       "      <td></td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>BERRIEN</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>17271</td>\n",
       "      <td>13019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172063</th>\n",
       "      <td>H-300-22262-479788</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SITTIG CRAWFISH LLC</td>\n",
       "      <td>EUNICE</td>\n",
       "      <td>LA</td>\n",
       "      <td>70535</td>\n",
       "      <td>2</td>\n",
       "      <td>12.45</td>\n",
       "      <td>...</td>\n",
       "      <td>70535</td>\n",
       "      <td></td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>ACADIA</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>12981</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172064</th>\n",
       "      <td>H-300-22262-479833</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SITTIG CRAWFISH LLC</td>\n",
       "      <td>EUNICE</td>\n",
       "      <td>LA</td>\n",
       "      <td>70535</td>\n",
       "      <td>4</td>\n",
       "      <td>12.45</td>\n",
       "      <td>...</td>\n",
       "      <td>70535</td>\n",
       "      <td></td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>ACADIA</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>12981</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172065</th>\n",
       "      <td>H-300-22262-480426</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GERALD GUILLORY FARMS</td>\n",
       "      <td>EUNICE</td>\n",
       "      <td>LA</td>\n",
       "      <td>70535</td>\n",
       "      <td>4</td>\n",
       "      <td>12.45</td>\n",
       "      <td>...</td>\n",
       "      <td>70535</td>\n",
       "      <td></td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>ST LANDRY</td>\n",
       "      <td>INDIVIDUAL EMPLOYER</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>12989</td>\n",
       "      <td>22097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172066</th>\n",
       "      <td>H-300-22263-483158</td>\n",
       "      <td>DETERMINATION ISSUED - CERTIFICATION</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ALEX T DUFURRENA</td>\n",
       "      <td>WINNEMUCCA</td>\n",
       "      <td>NV</td>\n",
       "      <td>89445</td>\n",
       "      <td>4</td>\n",
       "      <td>1807.23</td>\n",
       "      <td>...</td>\n",
       "      <td>89445</td>\n",
       "      <td></td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>HUMBOLDT</td>\n",
       "      <td>ASSOCIATION - AGENT</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>10513</td>\n",
       "      <td>32013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19088 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               case_number                           case_status  \\\n",
       "152979  H-300-21162-392244  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152980  H-300-21194-457735  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152981  H-300-21221-510019  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152982  H-300-21223-516656  DETERMINATION ISSUED - CERTIFICATION   \n",
       "152983  H-300-21224-517089  DETERMINATION ISSUED - CERTIFICATION   \n",
       "...                    ...                                   ...   \n",
       "172062  H-300-22262-479583  DETERMINATION ISSUED - CERTIFICATION   \n",
       "172063  H-300-22262-479788  DETERMINATION ISSUED - CERTIFICATION   \n",
       "172064  H-300-22262-479833  DETERMINATION ISSUED - CERTIFICATION   \n",
       "172065  H-300-22262-480426  DETERMINATION ISSUED - CERTIFICATION   \n",
       "172066  H-300-22263-483158  DETERMINATION ISSUED - CERTIFICATION   \n",
       "\n",
       "       certification_begin_date certification_end_date  \\\n",
       "152979                                                   \n",
       "152980                                                   \n",
       "152981                                                   \n",
       "152982                                                   \n",
       "152983                                                   \n",
       "...                         ...                    ...   \n",
       "172062                                                   \n",
       "172063                                                   \n",
       "172064                                                   \n",
       "172065                                                   \n",
       "172066                                                   \n",
       "\n",
       "                       employer_name employer_city employer_state  \\\n",
       "152979      MIDWEST AG ELECTRIC INC.   ALBERT LEA              MN   \n",
       "152980  ALTENBURG CONSTRUCTION, INC.    LEWISVILLE             MN   \n",
       "152981             PANCOST RANCH LLC      STONEHAM             CO   \n",
       "152982                LA ALIANZA, LP        NIPOMO             CA   \n",
       "152983                RC PACKING LLC      GONZALEZ             CA   \n",
       "...                              ...           ...            ...   \n",
       "172062              A & R FARMS, LLC       ALAPAHA             GA   \n",
       "172063           SITTIG CRAWFISH LLC        EUNICE             LA   \n",
       "172064           SITTIG CRAWFISH LLC        EUNICE             LA   \n",
       "172065         GERALD GUILLORY FARMS        EUNICE             LA   \n",
       "172066              ALEX T DUFURRENA    WINNEMUCCA             NV   \n",
       "\n",
       "       employer_postal_code nbr_workers_certified wage_rate  ... worksite_zip  \\\n",
       "152979                56007                     6     14.72  ...        56039   \n",
       "152980                56060                     7     15.37  ...        50436   \n",
       "152981                80754                     1   1727.75  ...        80754   \n",
       "152982                93444                    80     16.05  ...        92233   \n",
       "152983                93926                   215     13.85  ...        85365   \n",
       "...                     ...                   ...       ...  ...          ...   \n",
       "172062                31622                     1     11.99  ...        31622   \n",
       "172063                70535                     2     12.45  ...        70535   \n",
       "172064                70535                     4     12.45  ...        70535   \n",
       "172065                70535                     4     12.45  ...        70535   \n",
       "172066                89445                     4   1807.23  ...        89445   \n",
       "\n",
       "       primary_sub job_begin_date job_end_date worksite_county  \\\n",
       "152979                 2021-08-10   2022-04-01          MARTIN   \n",
       "152980                 2021-09-10   2021-12-31       WINNEBAGO   \n",
       "152981                 2021-11-01   2022-02-28            WELD   \n",
       "152982                 2021-10-11   2022-01-29        IMPERIAL   \n",
       "152983                 2021-10-25   2022-04-15            YUMA   \n",
       "...            ...            ...          ...             ...   \n",
       "172062                 2022-12-01   2023-04-01         BERRIEN   \n",
       "172063                 2022-12-01   2023-08-31          ACADIA   \n",
       "172064                 2022-12-01   2023-07-15          ACADIA   \n",
       "172065                 2022-12-02   2023-09-02       ST LANDRY   \n",
       "172066                 2022-12-01   2023-01-31        HUMBOLDT   \n",
       "\n",
       "       type_of_employer_application h2a_labor_contractor nbr_workers_needed  \\\n",
       "152979          INDIVIDUAL EMPLOYER                    Y                  6   \n",
       "152980          INDIVIDUAL EMPLOYER                    Y                  7   \n",
       "152981          ASSOCIATION - AGENT                    N                  1   \n",
       "152982               JOINT EMPLOYER                    Y                 80   \n",
       "152983          INDIVIDUAL EMPLOYER                    Y                215   \n",
       "...                             ...                  ...                ...   \n",
       "172062          INDIVIDUAL EMPLOYER                    N                  1   \n",
       "172063          INDIVIDUAL EMPLOYER                    N                  2   \n",
       "172064          INDIVIDUAL EMPLOYER                    N                  4   \n",
       "172065          INDIVIDUAL EMPLOYER                    N                  4   \n",
       "172066          ASSOCIATION - AGENT                    N                  4   \n",
       "\n",
       "           id   fips  \n",
       "152979  15092  27091  \n",
       "152980  21320  19189  \n",
       "152981  17049  08123  \n",
       "152982  21321  06025  \n",
       "152983  10874  04027  \n",
       "...       ...    ...  \n",
       "172062  17271  13019  \n",
       "172063  12981  22001  \n",
       "172064  12981  22001  \n",
       "172065  12989  22097  \n",
       "172066  10513  32013  \n",
       "\n",
       "[19088 rows x 29 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2a_df_final[h2a_df_final['fiscal_year'] == '2022']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h-2a-paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
