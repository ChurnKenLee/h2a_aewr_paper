{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.api.types import union_categoricals\n",
    "from itertools import islice\n",
    "import re\n",
    "import addfips\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "DC_STATEHOOD = 1 # Enables DC to be included in the state list\n",
    "import us\n",
    "import pickle\n",
    "import rapidfuzz\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned H-2A data; duplicate master entries, e.g., NCGA applications, are removed\n",
    "df = pd.read_parquet(\"../binaries/h2a_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numbers\n",
    "def replace_numbers(name):\n",
    "    # Define a dictionary of abbreviations and their replacements\n",
    "    abbreviations = {\n",
    "        r'\\bONE\\b': '1',\n",
    "        r'\\bTWO\\b': '2',\n",
    "        r'\\bTHREE\\b': '3',\n",
    "        r'\\bFOUR\\b': '4',\n",
    "        r'\\bFIVE\\b': '5',\n",
    "        r'\\bSIX\\b': '6',\n",
    "        r'\\bSEVEN\\b': '7',\n",
    "        r'\\bEIGHT\\b': '8',\n",
    "        r'\\bNINE\\b': '9',\n",
    "        r'\\bZERO\\b': '0',\n",
    "    }\n",
    "    \n",
    "    # Iterate over the abbreviations and replace them in the name\n",
    "    for abbr, replacement in abbreviations.items():\n",
    "        name = re.sub(abbr, replacement, name)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize common abbreviations\n",
    "def harmonize_abbreviations(name):\n",
    "    # Define a dictionary of abbreviations and their replacements\n",
    "    abbreviations = {\n",
    "        r'\\bINCORPORATED\\b': 'INC',\n",
    "        r'\\bCORPORATION\\b': 'CORP',\n",
    "        r'\\bLIMITED\\b': 'LTD',\n",
    "        r'\\bDOING BUSINESS AS\\b': 'DBA',\n",
    "        r'\\bCORPORATION\\b': 'CORP',\n",
    "        r'\\bLIMITED LIABILITY COMPANY': 'LLC',\n",
    "        r'\\bLIMITED LIABILITY PARTNERSHIP': 'LLP'\n",
    "    }\n",
    "    \n",
    "    # Iterate over the abbreviations and replace them in the name\n",
    "    for abbr, replacement in abbreviations.items():\n",
    "        name = re.sub(abbr, replacement, name)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove common terms that are not useful for matching\n",
    "def remove_common_terms(name):\n",
    "    # Define a dictionary of abbreviations and their replacements\n",
    "    abbreviations = {\n",
    "        r'\\bINC\\b': '',\n",
    "        r'\\bCORP\\b': '',\n",
    "        r'\\bLTD\\b': '',\n",
    "        r'\\bDBA\\b': '',\n",
    "        r'\\bCORP\\b': '',\n",
    "        r'\\bPARTNERSHIP\\b': '',\n",
    "        r'\\bFARM\\b': '',\n",
    "        r'\\bFARMS\\b': '',\n",
    "        r'\\bHARVESTING\\b': '',\n",
    "        r'\\bLLC\\b': '',\n",
    "        r'\\bLLP\\b': '',\n",
    "        r'\\bCOMPANY\\b': ''\n",
    "    }\n",
    "\n",
    "    # Iterate over the abbreviations and replace them in the name\n",
    "    for abbr, replacement in abbreviations.items():\n",
    "        name = re.sub(abbr, replacement, name)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean employer names for string similarity clustering\n",
    "# Replace mising with empty string\n",
    "df['cleaned_employer_name'] = df['employer_name'].fillna(\"\")\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numbers with letters\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].apply(lambda x: replace_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip special characters, replace with whitespace\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].str.replace(pat = r'[^A-Z0-9\\s]', repl = \" \", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize abbreviations\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].apply(lambda x: harmonize_abbreviations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove common terms that are not useful for matching\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].apply(lambda x: remove_common_terms(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize whitespace\n",
    "df['cleaned_employer_name'] = df['cleaned_employer_name'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns we want, drop duplicates\n",
    "names_df = df[['cleaned_employer_name', 'employer_postal_code']]\n",
    "names_df = names_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to group employer names by string similarity\n",
    "def group_by_similarity(strings, threshold=90):\n",
    "    groups = defaultdict(list)\n",
    "    \n",
    "    for string in strings:\n",
    "        matched = False\n",
    "        \n",
    "        for key in groups.keys():\n",
    "            if fuzz.WRatio(string, key) >= threshold:\n",
    "                groups[key].append(string)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            groups[string].append(string)\n",
    "    \n",
    "    return dict(groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to assign the same harmonized name to each group\n",
    "def assign_group_name(employer_name, grouped_names):\n",
    "\n",
    "    for group_name, employer_name_list in grouped_names.items():\n",
    "\n",
    "        if employer_name in employer_name_list:\n",
    "            return group_name\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_names_df = pd.DataFrame()\n",
    "# We restrict employer name matching to employers within the same ZIP code\n",
    "list_of_postal_codes = names_df['employer_postal_code'].unique()\n",
    "for postal_code in list_of_postal_codes:\n",
    "\n",
    "    match_df = names_df[names_df['employer_postal_code'] == postal_code].copy()\n",
    "    grouped_names = group_by_similarity(match_df['cleaned_employer_name'])\n",
    "    match_df['group_name'] = match_df['cleaned_employer_name'].apply(lambda x: assign_group_name(x, grouped_names))\n",
    "\n",
    "    grouped_names_df = pd.concat([grouped_names_df, match_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add group names back in\n",
    "names_df = names_df.merge(grouped_names_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add group names to original data, add employer ID, and re-export\n",
    "df = df.merge(names_df, how='left')\n",
    "df['employer_id'] = df.groupby(['group_name', 'employer_postal_code']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../files_for_phil/h2a_cleaned_with_grouped_employer_names.parquet\")\n",
    "df.to_parquet(\"../binaries/h2a_cleaned_with_grouped_employer_names.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
